{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "679Lmwt3l1Bk"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Networks \n",
    "## Session 23a\n",
    "\n",
    "##  Convolutional Neural Network (CNN)\n",
    "- Fashion MNIST\n",
    "- Dataset From CSV File\n",
    "\n",
    "<img src='../../images/prasami_color_tutorials_small.png' style = 'width:400px;' alt=\"By Pramod Sharma : pramod.sharma@prasami.com\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iAve6DCL4JH4"
   },
   "outputs": [],
   "source": [
    "###-----------------\n",
    "### Import Libraries\n",
    "###-----------------\n",
    "\n",
    "import os\n",
    "#import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###----------------------\n",
    "### Some basic parameters\n",
    "###----------------------\n",
    "\n",
    "\n",
    "inpDir = '../../input' # location where input data is stored\n",
    "outDir = '../output' # location to store outputs\n",
    "modelDir = '../models'\n",
    "subDir = 'fashion_mnist'\n",
    "\n",
    "RANDOM_STATE = 24 # for initialization ----- REMEMBER: to remove at the time of promotion to production\n",
    "tf.random.set_seed(RANDOM_STATE) # setting for Tensorflow as well\n",
    "\n",
    "\n",
    "EPOCHS = 10 # number of cycles to run\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32 # inline of Traing Rows being 60000\n",
    "\n",
    "# Set parameters for decoration of plots\n",
    "params = {'legend.fontsize' : 'large',\n",
    "          'figure.figsize'  : (15,10),\n",
    "          'axes.labelsize'  : 'x-large',\n",
    "          'axes.titlesize'  :'x-large',\n",
    "          'xtick.labelsize' :'large',\n",
    "          'ytick.labelsize' :'large',\n",
    "         }\n",
    "\n",
    "CMAP = plt.cm.coolwarm\n",
    "\n",
    "plt.rcParams.update(params) # update rcParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Hygiene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iAve6DCL4JH4"
   },
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (physical_devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_verify_dir(_path : str):\n",
    "    '''\n",
    "    Arg:\n",
    "        path: path to verify the directory\n",
    "    returns:\n",
    "        create dir if it does not exists\n",
    "    '''\n",
    "    if os.path.exists(_path): # check if the path exists. Maybe a file or a folder\n",
    "        \n",
    "        print(_path, ' exists') # advised the user\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        os.makedirs(_path) # create the path\n",
    "        \n",
    "        print(\"Created folder : \", _path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###-----------------------------------\n",
    "### Function to plot Loss Curve\n",
    "###-----------------------------------\n",
    "\n",
    "def fn_plot_tf_hist(hist_df : pd.DataFrame):\n",
    "    '''\n",
    "    Args:\n",
    "      hist_df : pandas Dataframe with four columns\n",
    "                For 'x' values, we will use index\n",
    "    '''\n",
    "    fig, axes = plt.subplots(1,2 , figsize = (15,6))\n",
    "\n",
    "    # properties  matplotlib.patch.Patch \n",
    "    props = dict(boxstyle='round', facecolor='aqua', alpha=0.4)\n",
    "    facecolor = 'cyan'\n",
    "    fontsize=12\n",
    "    \n",
    "    # Get columns by index to eliminate any column naming error\n",
    "    y1 = hist_df.columns[0]\n",
    "    y2 = hist_df.columns[1]\n",
    "    y3 = hist_df.columns[2]\n",
    "    y4 = hist_df.columns[3]\n",
    "\n",
    "    # Where was min loss\n",
    "    best = hist_df[hist_df[y3] == hist_df[y3].min()]\n",
    "    \n",
    "    ax = axes[0]\n",
    "\n",
    "    hist_df.plot(y = [y1,y3], ax = ax, colormap=CMAP)\n",
    "\n",
    "\n",
    "    # little beautification\n",
    "    txtFmt = \"Loss: \\n  train: {:6.4f}\\n   test: {:6.4f}\"\n",
    "    txtstr = txtFmt.format(hist_df.iloc[-1][y1],\n",
    "                           hist_df.iloc[-1][y3]) #text to plot\n",
    "    \n",
    "    # place a text box in upper middle in axes coords\n",
    "    ax.text(0.3, 0.95, txtstr, transform=ax.transAxes, fontsize=fontsize,\n",
    "            verticalalignment='top', bbox=props)\n",
    "\n",
    "    # Mark arrow at lowest\n",
    "    ax.annotate(f'Min: {best[y3].to_numpy()[0]:6.4f}', # text to print\n",
    "                xy=(best.index.to_numpy(), best[y3].to_numpy()[0]), # Arrow start\n",
    "                xytext=(best.index.to_numpy()-1, best[y3].to_numpy()[0]), # location of text \n",
    "                fontsize=fontsize, va='bottom', ha='right',bbox=props, # beautification of text\n",
    "                arrowprops=dict(facecolor=facecolor, shrink=0.05)) # arrow\n",
    "\n",
    "    # Draw vertical line at best value\n",
    "    ax.axvline(x = best.index.to_numpy(), color = 'green', linestyle='-.', lw = 3);\n",
    "\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "    ax.set_ylabel(y1.capitalize())\n",
    "    ax.set_title('Errors')\n",
    "    ax.grid();\n",
    "    ax.legend(loc = 'upper left') # model legend to upper left\n",
    "\n",
    "    ax = axes[1]\n",
    "\n",
    "    hist_df.plot( y = [y2, y4], ax = ax, colormap=CMAP)\n",
    "    \n",
    "    # little beautification\n",
    "    txtFmt = \"Accuracy: \\n  train: {:6.4f}\\n  test:  {:6.4f}\"\n",
    "    txtstr = txtFmt.format(hist_df.iloc[-1][y2],\n",
    "                           hist_df.iloc[-1][y4]) #text to plot\n",
    "\n",
    "    # place a text box in upper middle in axes coords\n",
    "    ax.text(0.3, 0.2, txtstr, transform=ax.transAxes, fontsize=fontsize,\n",
    "            verticalalignment='top', bbox=props)\n",
    "\n",
    "    # Mark arrow at lowest\n",
    "    ax.annotate(f'Best: {best[y4].to_numpy()[0]:6.4f}', # text to print\n",
    "                xy=(best.index.to_numpy(), best[y4].to_numpy()[0]), # Arrow start\n",
    "                xytext=(best.index.to_numpy()-1, best[y4].to_numpy()[0]), # location of text \n",
    "                fontsize=fontsize, va='bottom', ha='right',bbox=props, # beautification of text\n",
    "                arrowprops=dict(facecolor=facecolor, shrink=0.05)) # arrow\n",
    "    \n",
    "    \n",
    "    # Draw vertical line at best value\n",
    "    ax.axvline(x = best.index.to_numpy(), color = 'green', linestyle='-.', lw = 3);\n",
    "\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "    ax.set_ylabel(y2.capitalize())\n",
    "    ax.grid()\n",
    "    ax.legend(loc = 'lower left')\n",
    "    \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_plot_label(train_df : pd.DataFrame, test_df : pd.DataFrame):\n",
    "    \n",
    "    plt.figure(figsize = (15,5))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "\n",
    "    ax = train_df['label'].value_counts().plot(kind='bar',\n",
    "                                               title=\"Training distribution\",\n",
    "                                               color = 'DarkBlue', alpha = 0.8)\n",
    "\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    \n",
    "    ax = test_df['label'].value_counts().plot(kind='bar',\n",
    "                                              title=\"Testing distribution\",\n",
    "                                              color = 'Orange', alpha = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRFxccghyMVo"
   },
   "source": [
    "## Using MNIST Fashion data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels\n",
    "\n",
    "Total : 785 columns\n",
    "First column is label remaining columns are pixel values of the images.\n",
    "\n",
    "Each training and test example is assigned to one of the following labels:\n",
    "\n",
    "\n",
    "|Label| Class\n",
    "|:-|:-|\n",
    "0 | T-shirt/top\n",
    "1 | Trouser\n",
    "2 | Pullover\n",
    "3 | Dress\n",
    "4 | Coat\n",
    "5 | Sandal\n",
    "6 | Shirt\n",
    "7 | Sneaker\n",
    "8 | Bag\n",
    "9 | Ankle boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels ={0 : 'T-shirt/top',\n",
    "               1 : 'Trouser',\n",
    "               2 : 'Pullover',\n",
    "               3 : 'Dress',\n",
    "               4 : 'Coat',\n",
    "               5 : 'Sandal',\n",
    "               6 : 'Shirt',\n",
    "               7 : 'Sneaker',\n",
    "               8 : 'Bag',\n",
    "               9 : 'Ankle boot'\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = os.path.join(inpDir, subDir, 'fashion-mnist_train.csv')\n",
    "test_filename = os.path.join(inpDir, subDir, 'fashion-mnist_test.csv')\n",
    "\n",
    "train_df = pd.read_csv(train_filename, header = 0)\n",
    "test_df = pd.read_csv(test_filename, header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_plot_label(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each row need to be seperated in features and labels\n",
    "def split_feature_label(row ):\n",
    "    '''\n",
    "    Args:\n",
    "        row: array of 785 values\n",
    "    returns:\n",
    "        feature : np.ndarray of shape (28 x 28, 1)\n",
    "        label: integer\n",
    "    '''\n",
    "    \n",
    "    feature = tf.reshape(row[1:], [28, 28, 1])\n",
    "    \n",
    "    label = row[0]\n",
    "    \n",
    "    return feature, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training dataset\n",
    "tmp_ds = tf.data.Dataset.from_tensor_slices(train_df)\n",
    "\n",
    "train_ds = tmp_ds.map(split_feature_label)\n",
    "\n",
    "train_ds = train_ds.batch(BATCH_SIZE)\n",
    "\n",
    "tmp_ds = tf.data.Dataset.from_tensor_slices(test_df)\n",
    "\n",
    "test_ds = tmp_ds.map(split_feature_label)\n",
    "\n",
    "test_ds = test_ds.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wArwCTJJlUa"
   },
   "source": [
    "### Verify the data\n",
    "\n",
    "To verify that the dataset looks correct, let's plot the first 25 images from the training set and display the class name below each image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_ds.take(1): # gets a batch of first BATCH_SIZE images\n",
    "    \n",
    "    for i in range(BATCH_SIZE):\n",
    "        \n",
    "        plt.subplot(4,int(BATCH_SIZE/4),i+1)\n",
    "        \n",
    "        plt.grid(False)\n",
    "        \n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"), cmap=plt.cm.binary)\n",
    "        \n",
    "        plt.title(class_labels[labels[i].numpy()])\n",
    "        \n",
    "        plt.text(2, 4, labels[i].numpy(), color='b', fontsize=12)\n",
    "        \n",
    "        plt.axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in test_ds.take(1): # gets a batch of first BATCH_SIZE images\n",
    "    \n",
    "    for i in range(BATCH_SIZE):\n",
    "        \n",
    "        plt.subplot(4,int(BATCH_SIZE/4),i+1)\n",
    "        \n",
    "        plt.grid(False)\n",
    "        \n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"), cmap=plt.cm.binary)\n",
    "        \n",
    "        plt.title(class_labels[labels[i].numpy()])\n",
    "        \n",
    "        plt.text(2, 4, labels[i].numpy(), color='b', fontsize=12)\n",
    "        \n",
    "        plt.axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescaling of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "image_batch, labels_batch = next(iter(train_ds))\n",
    "\n",
    "img = image_batch[0].numpy()\n",
    "\n",
    "print ('Original Image--- Min pixel:', img.min(), ' | Max pixel:', img.max())\n",
    "\n",
    "print ('-'*50)\n",
    "\n",
    "\n",
    "# apply it to the dataset by calling map\n",
    "\n",
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "\n",
    "img = image_batch[0].numpy()\n",
    "\n",
    "print ('Normalized Image--- Min pixel:', img.min(), ' | Max pixel:', img.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optimize for performance\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Layer in Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1, 6, 6, 1)\n",
    "X = tf.random.normal(input_shape)\n",
    "#X = tf.fill(input_shape, 1.0)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(X.numpy()[0,:,:,0], annot=True, fmt=\".2f\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.constant_initializer(1.).value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.keras.layers.Conv2D(1, 3,\n",
    "                           kernel_initializer=tf.constant_initializer(1.),\n",
    "                           use_bias = False,\n",
    "                           activation='relu', \n",
    "                           input_shape=input_shape[1:])(X)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arguments|Description\n",
    ":--|:--\n",
    "filters|Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).\n",
    "kernel_size|An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions.\n",
    "strides|An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.\n",
    "padding|one of \"valid\" or \"same\" (case-insensitive).\n",
    "data_format|A string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch_size, height, width, channels) while channels_first corresponds to inputs with shape (batch_size, channels,height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be channels_last.\n",
    "dilation_rate|an integer or tuple/list of 2 integers, specifying the dilation rate to use for dilated convolution. Can be a single integer to specify the same value for all spatial dimensions. Currently, specifying any dilation_rate value != 1 is incompatible with specifying any stride value != 1.\n",
    "groups|A positive integer specifying the number of groups in which the input is split along the channel axis. Each group is convolved separately with filters / groups filters. The output is the concatenation of all the groups results along the channel axis. Input channels and filters must both be divisible by groups.\n",
    "activation|Activation function to use. If you don't specify anything, no activation is applied (see keras.activations).\n",
    "use_bias|Boolean, whether the layer uses a bias vector.\n",
    "kernel_initializer|Initializer for the kernel weights matrix (see keras.initializers).\n",
    "bias_initializer|Initializer for the bias vector (see keras.initializers).\n",
    "kernel_regularizer|Regularizer function applied to the kernel weights matrix (see keras.regularizers).\n",
    "bias_regularizer|Regularizer function applied to the bias vector (see keras.regularizers).\n",
    "activity_regularizer|Regularizer function applied to the output of the layer (its \"activation\") (see keras.regularizers).\n",
    "kernel_constraint|Constraint function applied to the kernel matrix (see keras.constraints).\n",
    "bias_constraint|Constraint function applied to the bias vector (see keras.constraints)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(y.numpy()[0,:,:,0], annot=True, fmt=\".2f\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaxPool Layer in Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n",
    "                                           strides=(2, 2), \n",
    "                                           padding='valid')\n",
    "\n",
    "z = max_pool_2d(y)\n",
    "\n",
    "sns.heatmap(z.numpy()[0,:,:,0], annot=True, fmt=\".2f\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling Layer\n",
    ">tf.keras.layers.MaxPool2D(\n",
    "    pool_size=(2, 2), strides=None, padding='valid', data_format=None, **kwargs\n",
    ")\n",
    "\n",
    "Arguments|Description\n",
    ":--|:--\n",
    "pool_size|integer or tuple of 2 integers, window size over which to take the maximum. (2, 2) will take the max value over a 2x2 pooling window. If only one integer is specified, the same window length will be used for both dimensions.\n",
    "strides|Integer, tuple of 2 integers, or None. Strides values. Specifies how far the pooling window moves for each pooling step. If None, it will default to pool_size.\n",
    "padding|One of \"valid\" or \"same\" (case-insensitive). \"valid\" adds no zero padding. \"same\" adds padding such that if the stride is 1, the output shape is the same as input shape.\n",
    "data_format|A string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be \"channels_last\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oewp-wYg31t9"
   },
   "source": [
    "### Create the Convolution base\n",
    "\n",
    "<img src = '../../images/dnn_nb_cnn_MNIST.png' style = 'width:800px;' alt=\"Demo Convolution Network MNIST\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">tf.keras.layers.Conv2D(\n",
    "    filters, kernel_size, strides=(1, 1), padding='valid', data_format=None,\n",
    "    dilation_rate=(1, 1), groups=1, activation=None, use_bias=True,\n",
    "    kernel_initializer='glorot_uniform', bias_initializer='zeros',\n",
    "    kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None,\n",
    "    kernel_constraint=None, bias_constraint=None, **kwargs\n",
    ")\n",
    "\n",
    ">tf.keras.layers.MaxPool2D(\n",
    "    pool_size=(2, 2), strides=None, padding='valid', data_format=None, **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel (weight initialization)\n",
    "krnl_init = tf.keras.initializers.GlorotUniform( seed = RANDOM_STATE)\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add( tf.keras.layers.Rescaling(1./255) )\n",
    "\n",
    "# Convolution 1\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), # number of filters and filter size\n",
    "                                 kernel_initializer = krnl_init,\n",
    "                                 padding='same', \n",
    "                                 activation='relu',\n",
    "                                 input_shape=(28, 28, 1))) # (28 x 28 x 32)\n",
    "# Pool 1\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2))) # (14 x 14 x 32)\n",
    "\n",
    "# Convolution 2\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3),\n",
    "                                 kernel_initializer = krnl_init,\n",
    "                                 activation='relu')) # (12 x 12 x 64)\n",
    "\n",
    "# Pool 2\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2))) # ( 6 x 6 x 64)\n",
    "\n",
    "# Convolution 3\n",
    "model.add(tf.keras.layers.Conv2D(128, (3, 3),\n",
    "                                 kernel_initializer = krnl_init,\n",
    "                                 activation = 'relu' ) ) # ( 4 x 4 x 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mRs95d6LUVEi"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# Dense 1\n",
    "model.add(tf.keras.layers.Dense(64,\n",
    "                                kernel_initializer = krnl_init,\n",
    "                                activation='relu'))\n",
    "# Dense 2\n",
    "model.add(tf.keras.layers.Dense(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3odqfHP4M67"
   },
   "source": [
    "### Compile and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MdDzI75PUXrG"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_ds,\n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8-C4XBg4UTJy"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(history.history)\n",
    "res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_plot_tf_hist(res_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKgyC5K_4O0d"
   },
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gtyDF0MKUcM7"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_ds, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = tf.concat([y for x, y in test_ds], axis=0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(test_ds)\n",
    "\n",
    "y_pred = yhat.argmax(axis = 1)\n",
    "\n",
    "print(f'Accuracy score on Test Data : {accuracy_score(y_test, y_pred) : .4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|| |Predicted| class\n",
    "|:-|:-|:-|:-|\n",
    "| | |P|N|\n",
    "Actual|P|TP|FN\n",
    "class|N|FP|TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMAP = plt.cm.Blues\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                       display_labels=class_labels.values())\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (6,6))\n",
    "\n",
    "disp.plot(ax = ax, cmap=CMAP, colorbar=False, xticks_rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results data plot\n",
    "\n",
    "test_df['y_pred'] = y_pred\n",
    "\n",
    "plot_df = test_df.sample(n = 50) # Take 50 sample from the training set\n",
    "\n",
    "fig = plt.figure(figsize=(15, 9))  # figure size in inches\n",
    "\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05) # adjust subplots\n",
    "\n",
    "i = 0\n",
    "\n",
    "fntsize = 12\n",
    "\n",
    "for _, row in plot_df.iterrows(): # iterate through all rows of the dataframe\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    image = row.values[1:-1].reshape(28,28) # reshape row to a 28x28 matrix\n",
    "    \n",
    "    if row[0]!= row[-1]:\n",
    "        color = 'red'\n",
    "    else:\n",
    "        color = 'cyan'\n",
    "        \n",
    "    props = dict(boxstyle='round', facecolor=color, alpha=0.5)\n",
    "    \n",
    "    ax = fig.add_subplot(5, 10, (i), xticks=[], yticks=[]) # add a subplot to the figure\n",
    "    \n",
    "    ax.imshow(image, cmap=plt.cm.binary, interpolation='nearest') # show image on the axis\n",
    "    \n",
    "    ax.set_title(class_labels[row[0]], fontsize=fntsize)   # add number (class) of the image\n",
    "    \n",
    "    ax.text(0.1, 0.95, class_labels[row[-1]], transform=ax.transAxes, fontsize=12,\n",
    "            verticalalignment='top', bbox=props)   # add number (class) of the image\n",
    "    \n",
    "fig.suptitle('Predictions\\nIncorrect classes are marked in red.')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cnn.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
